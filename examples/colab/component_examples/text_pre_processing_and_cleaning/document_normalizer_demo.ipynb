{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"document_normalizer_demo.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNcj24SjrMUuxp/lOA28j5F"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"uXIWSN300w5v"},"source":["\n","![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n","\n","[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/nlu/blob/master/examples/colab/component_examples/text_pre_processing_and_cleaning/document_normalizer_demo.ipynb)\n","\n","\n","\n","The DocumentNormalizer extracts content from HTML or XML documents, applying either data cleansing using an arbitrary number of custom regular expressions either data extraction following the different parameters"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"abuB9K1_QVuL","executionInfo":{"status":"ok","timestamp":1610693754293,"user_tz":-60,"elapsed":91245,"user":{"displayName":"Christian Kasim Loan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjqAD-ircKP-s5Eh6JSdkDggDczfqQbJGU_IRb4Hw=s64","userId":"14469489166467359317"}},"outputId":"966d31fc-ea36-43e5-fc24-70dadcd55aab"},"source":["import os\n","! apt-get update -qq > /dev/null   \n","# Install java\n","! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n","! pip install pyspark==2.4.7\n","! pip install --index-url https://test.pypi.org/simple/ --extra-index-url https://pypi.org/simple peanutbutterdatatime==1.1.0rc24\n","import nlu\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting pyspark==2.4.7\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e2/06/29f80e5a464033432eedf89924e7aa6ebbc47ce4dcd956853a73627f2c07/pyspark-2.4.7.tar.gz (217.9MB)\n","\u001b[K     |████████████████████████████████| 217.9MB 53kB/s \n","\u001b[?25hCollecting py4j==0.10.7\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/53/c737818eb9a7dc32a7cd4f1396e787bd94200c3997c72c1dbe028587bd76/py4j-0.10.7-py2.py3-none-any.whl (197kB)\n","\u001b[K     |████████████████████████████████| 204kB 37.6MB/s \n","\u001b[?25hBuilding wheels for collected packages: pyspark\n","  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyspark: filename=pyspark-2.4.7-py2.py3-none-any.whl size=218279465 sha256=a2ab3bd5fde1760f86f685f178ad4fbbdbd53e471907a5d7e738e4c93ca8f622\n","  Stored in directory: /root/.cache/pip/wheels/34/1f/2e/1e7460f80acf26b08dbb8c53d7ff9e07146f2a68dd5c732be5\n","Successfully built pyspark\n","Installing collected packages: py4j, pyspark\n","Successfully installed py4j-0.10.7 pyspark-2.4.7\n","Looking in indexes: https://test.pypi.org/simple/, https://pypi.org/simple\n","Collecting peanutbutterdatatime==1.1.0rc24\n","\u001b[?25l  Downloading https://test-files.pythonhosted.org/packages/a2/45/c18cbfef74be9b22f58d236102d3933db766b332c3a9f7501c79a0aaaaef/peanutbutterdatatime-1.1.0rc24-py3-none-any.whl (175kB)\n","\u001b[K     |████████████████████████████████| 184kB 4.8MB/s \n","\u001b[?25hCollecting pyarrow>=0.16.0\n","\u001b[?25l  Downloading https://test-files.pythonhosted.org/packages/d7/e1/27958a70848f8f7089bff8d6ebe42519daf01f976d28b481e1bfd52c8097/pyarrow-2.0.0-cp36-cp36m-manylinux2014_x86_64.whl (17.7MB)\n","\u001b[K     |████████████████████████████████| 17.7MB 247kB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from peanutbutterdatatime==1.1.0rc24) (1.19.5)\n","Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from peanutbutterdatatime==1.1.0rc24) (0.8)\n","Collecting spark-nlp<2.8,>=2.7.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/1f/864678c262ed9312d7b182eda8bd2976fce2a2847e3a809aa54d92f7dace/spark_nlp-2.7.1-py2.py3-none-any.whl (138kB)\n","\u001b[K     |████████████████████████████████| 143kB 7.2MB/s \n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from peanutbutterdatatime==1.1.0rc24) (1.1.5)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->peanutbutterdatatime==1.1.0rc24) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->peanutbutterdatatime==1.1.0rc24) (2.8.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas->peanutbutterdatatime==1.1.0rc24) (1.15.0)\n","Installing collected packages: pyarrow, spark-nlp, peanutbutterdatatime\n","  Found existing installation: pyarrow 0.14.1\n","    Uninstalling pyarrow-0.14.1:\n","      Successfully uninstalled pyarrow-0.14.1\n","Successfully installed peanutbutterdatatime-1.1.0rc24 pyarrow-2.0.0 spark-nlp-2.7.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4SQzdgwyQ65Q","executionInfo":{"status":"ok","timestamp":1610696506963,"user_tz":-60,"elapsed":2562,"user":{"displayName":"Christian Kasim Loan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjqAD-ircKP-s5Eh6JSdkDggDczfqQbJGU_IRb4Hw=s64","userId":"14469489166467359317"}},"outputId":"f689174a-8b8f-41b8-9ca4-dd903489657f"},"source":["pipe = nlu.load('norm_document')\n","data = '<!DOCTYPE html> <html> <head> <title>Example</title> </head> <body> <p>This is an example of a simple HTML page with one paragraph.</p> </body> </html>'\n","df = pipe.predict(data,output_level='document')\n","print(df['normalized_document'])\n","print(df.iloc[0]['normalized_document'])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["origin_index\n","0    [ Example This is an example of a simple HTML ...\n","Name: normalized_document, dtype: object\n","[' Example This is an example of a simple HTML page with one paragraph.']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o73dDzocR7L_","executionInfo":{"status":"ok","timestamp":1610696506964,"user_tz":-60,"elapsed":2181,"user":{"displayName":"Christian Kasim Loan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjqAD-ircKP-s5Eh6JSdkDggDczfqQbJGU_IRb4Hw=s64","userId":"14469489166467359317"}},"outputId":"732fe2eb-c51e-4108-b5eb-aac6a88873ba"},"source":["pipe.print_info()\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["The following parameters are configurable for this NLU pipeline (You can copy paste the examples) :\n",">>> pipe['document_normalizer'] has settable params:\n","pipe['document_normalizer'].setAction('clean')           | Info: action to perform applying regex patterns on text | Currently set to : clean\n","pipe['document_normalizer'].setPatterns(['<[^>]*>'])     | Info: normalization regex patterns which match will be removed from document. Defaults is <[^>]*> | Currently set to : ['<[^>]*>']\n","pipe['document_normalizer'].setReplacement(' ')          | Info: replacement string to apply when regexes match | Currently set to :  \n","pipe['document_normalizer'].setLowercase(False)          | Info: whether to convert strings to lowercase | Currently set to : False\n","pipe['document_normalizer'].setPolicy('pretty_all')      | Info: policy to remove pattern from text | Currently set to : pretty_all\n","pipe['document_normalizer'].setEncoding('UTF-8')         | Info: file encoding to apply on normalized documents | Currently set to : UTF-8\n",">>> pipe['default_tokenizer'] has settable params:\n","pipe['default_tokenizer'].setTargetPattern('\\S+')        | Info: pattern to grab from text as token candidates. Defaults \\S+ | Currently set to : \\S+\n","pipe['default_tokenizer'].setContextChars(['.', ',', ';', ':', '!', '?', '*', '-', '(', ')', '\"', \"'\"])  | Info: character list used to separate from token boundaries | Currently set to : ['.', ',', ';', ':', '!', '?', '*', '-', '(', ')', '\"', \"'\"]\n","pipe['default_tokenizer'].setCaseSensitiveExceptions(True)  | Info: Whether to care for case sensitiveness in exceptions | Currently set to : True\n","pipe['default_tokenizer'].setMinLength(0)                | Info: Set the minimum allowed legth for each token | Currently set to : 0\n","pipe['default_tokenizer'].setMaxLength(99999)            | Info: Set the maximum allowed legth for each token | Currently set to : 99999\n",">>> pipe['document_assembler'] has settable params:\n","pipe['document_assembler'].setCleanupMode('shrink')      | Info: possible values: disabled, inplace, inplace_full, shrink, shrink_full, each, each_full, delete_full | Currently set to : shrink\n",">>> pipe['sentence_detector'] has settable params:\n","pipe['sentence_detector'].setUseAbbreviations(True)      | Info: whether to apply abbreviations at sentence detection | Currently set to : True\n","pipe['sentence_detector'].setDetectLists(True)           | Info: whether detect lists during sentence detection | Currently set to : True\n","pipe['sentence_detector'].setUseCustomBoundsOnly(False)  | Info: Only utilize custom bounds in sentence detection | Currently set to : False\n","pipe['sentence_detector'].setCustomBounds([])            | Info: characters used to explicitly mark sentence bounds | Currently set to : []\n","pipe['sentence_detector'].setExplodeSentences(False)     | Info: whether to explode each sentence into a different row, for better parallelization. Defaults to false. | Currently set to : False\n","pipe['sentence_detector'].setMinLength(0)                | Info: Set the minimum allowed length for each sentence. | Currently set to : 0\n","pipe['sentence_detector'].setMaxLength(99999)            | Info: Set the maximum allowed length for each sentence | Currently set to : 99999\n"],"name":"stdout"}]}]}